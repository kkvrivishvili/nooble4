# Conversation Service - Implementaci√≥n Completa

> **ACTUALIZACI√ìN**: Se ha migrado toda la comunicaci√≥n entre servicios de HTTP directo al patr√≥n pseudo-s√≠ncrono sobre Redis. Todos los clientes y workers ahora implementan el patr√≥n BaseWorker 4.0.

## üéØ Visi√≥n General

El Conversation Service es el n√∫cleo de memoria conversacional del sistema Nooble, dise√±ado para manejar conversaciones activas con integraci√≥n LangChain y persistencia h√≠brida Redis + PostgreSQL.

## üèóÔ∏è Arquitectura Refactorizada

### Integraci√≥n con Servicios

```
Agent Execution ‚îÄ‚îÄ‚îÄ‚îÄ(save_message)‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ Conversation Service
                                              ‚îÇ
Query Service ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ(get_context)‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂       ‚îÇ
                                              ‚îÇ
WebSocket Manager ‚îÄ(session_closed)‚îÄ‚îÄ‚ñ∂       ‚îÇ
                                              ‚ñº
                                        Redis (Activas)
                                              ‚îÇ
                                              ‚îÇ (30s despu√©s del cierre)
                                              ‚ñº
                                       PostgreSQL (Persistente)
                                              ‚îÇ
                                              ‚ñº
                                        Frontend/CRM (API REST)
```

### Componentes Principales

1. **ConversationService**: L√≥gica principal con integraci√≥n LangChain
2. **MemoryManager**: Gesti√≥n inteligente de memoria conversacional por modelo
3. **PersistenceManager**: Manejo h√≠brido Redis + PostgreSQL
4. **Specialized Workers**: MessageSaveWorker + MigrationWorker
5. **CRM API**: Endpoints REST para dashboard y estad√≠sticas

## üß† Integraci√≥n LangChain

### Estrategia de Memoria por Modelo

```python
model_strategies = {
    "llama3-8b-8192": ConversationTokenBufferMemory(max_token_limit=6000),
    "llama3-70b-8192": ConversationTokenBufferMemory(max_token_limit=6000), 
    "gpt-4": ConversationTokenBufferMemory(max_token_limit=28000),
    "claude-3-sonnet": ConversationSummaryBufferMemory(max_token_limit=120000)
}
```

### Optimizaci√≥n de Contexto

- **Token counting**: Estimaci√≥n precisa por mensaje
- **Truncamiento inteligente**: LangChain maneja autom√°ticamente
- **Context reservation**: 30% reservado para respuesta del modelo
- **Tier-aware limits**: Diferentes l√≠mites seg√∫n tier del usuario

## üìä Estructura de Datos

### Redis (Conversaciones Activas)

```
conversation:{tenant_id}:{conversation_id} ‚Üí Conversation JSON
messages:{conversation_id} ‚Üí List[Message] (LIFO)
session_conversation:{tenant_id}:{session_id} ‚Üí conversation_id
active_conversations:{tenant_id} ‚Üí Set[conversation_id]
```

### PostgreSQL (Preparado para Supabase)

```sql
-- Tabla principal de conversaciones
CREATE TABLE conversations (
    id UUID PRIMARY KEY,
    tenant_id VARCHAR NOT NULL,
    session_id VARCHAR NOT NULL,
    agent_id VARCHAR NOT NULL,
    user_id VARCHAR,
    model_name VARCHAR DEFAULT 'llama3-8b-8192',
    status VARCHAR DEFAULT 'active',
    message_count INTEGER DEFAULT 0,
    total_tokens INTEGER DEFAULT 0,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    last_message_at TIMESTAMP,
    migrated_from_redis BOOLEAN DEFAULT false
);

-- Tabla de mensajes
CREATE TABLE messages (
    id UUID PRIMARY KEY,
    conversation_id UUID REFERENCES conversations(id),
    role VARCHAR NOT NULL CHECK (role IN ('user', 'assistant', 'system', 'function')),
    content TEXT NOT NULL,
    tokens_estimate INTEGER,
    processing_time_ms INTEGER,
    agent_id VARCHAR,
    model_used VARCHAR,
    created_at TIMESTAMP DEFAULT NOW(),
    metadata JSONB
);

-- √çndices para performance
CREATE INDEX idx_conversations_tenant_id ON conversations(tenant_id);
CREATE INDEX idx_conversations_agent_id ON conversations(agent_id);  
CREATE INDEX idx_conversations_created_at ON conversations(created_at);
CREATE INDEX idx_messages_conversation_id ON messages(conversation_id);
CREATE INDEX idx_messages_created_at ON messages(created_at);
```

## üîÑ Domain Actions

### 1. save_message (desde Agent Execution)

```json
{
  "action_type": "conversation.save_message",
  "tenant_id": "tenant123",
  "session_id": "session_abc",
  "role": "assistant",
  "content": "Respuesta del agente...",
  "agent_id": "agent_xyz",
  "model_name": "llama3-70b-8192",
  "tokens_estimate": 150,
  "metadata": {
    "tenant_tier": "professional"
  }
}
```

### 2. get_context (desde Query Service)

```json
{
  "action_type": "conversation.get_context",
  "tenant_id": "tenant123", 
  "session_id": "session_abc",
  "model_name": "llama3-70b-8192",
  "tenant_tier": "professional"
}
```

### 3. session_closed (desde WebSocket Manager)

```json
{
  "action_type": "conversation.session_closed",
  "tenant_id": "tenant123",
  "session_id": "session_abc"
}
```

## üéöÔ∏è L√≠mites por Tier

| Tier | Conversaciones Activas | Mensajes/Conv | Retenci√≥n | Contexto |
|------|----------------------|---------------|-----------|-----------|
| Free | 3 | 50 | 7 d√≠as | 5 mensajes |
| Advance | 10 | 200 | 30 d√≠as | 15 mensajes |
| Professional | 50 | 1,000 | 90 d√≠as | 30 mensajes |
| Enterprise | Ilimitado | Ilimitado | 365 d√≠as | 50 mensajes |

## üöÄ Plan de Implementaci√≥n

### Fase 1: Core Implementation (Semana 1)
- [ ] Implementar ConversationService base
- [ ] Integrar MemoryManager con LangChain
- [ ] Configurar PersistenceManager para Redis
- [ ] Crear Domain Actions y Handlers
- [ ] Implementar ConversationWorker

### Fase 2: Persistence & Migration (Semana 2)  
- [ ] Preparar schema PostgreSQL/Supabase
- [ ] Implementar MigrationWorker
- [ ] Sistema de migraci√≥n autom√°tica Redis ‚Üí PostgreSQL
- [ ] Error handling y retry logic
- [ ] Testing de persistencia

### Fase 3: CRM Integration (Semana 3)
- [ ] Endpoints REST para CRM
- [ ] Listado de conversaciones con filtros
- [ ] Vista completa de conversaci√≥n
- [ ] Estad√≠sticas b√°sicas por tenant/agente
- [ ] Dashboard data endpoints

### Fase 4: Optimization & Production (Semana 4)
- [ ] Performance tuning
- [ ] Monitoring y m√©tricas
- [ ] Cleanup autom√°tico de datos antiguos
- [ ] Load testing
- [ ] Documentation final

## ‚öôÔ∏è Configuraci√≥n de Desarrollo

### Variables de Entorno

```env
# Conversation Service
CONVERSATION_REDIS_URL=redis://localhost:6379/0
CONVERSATION_DATABASE_URL=postgresql://user:pass@localhost/conversations
CONVERSATION_SUPABASE_URL=https://xyz.supabase.co
CONVERSATION_SUPABASE_KEY=eyJ...

# LangChain
CONVERSATION_LANGCHAIN_MEMORY_TYPE=token_buffer
CONVERSATION_WEBSOCKET_GRACE_PERIOD=30

# Workers
CONVERSATION_MESSAGE_SAVE_WORKER_BATCH_SIZE=50
CONVERSATION_PERSISTENCE_MIGRATION_INTERVAL=60
```

### Instalaci√≥n

```bash
cd conversation_service
pip install -r requirements.txt

# Para desarrollo con auto-reload
uvicorn main:app --reload --port 8004

# Para producci√≥n
uvicorn main:app --host 0.0.0.0 --port 8004 --workers 4
```

## üìà Recomendaciones de Performance

### Escalabilidad

- **Redis Clustering**: Para > 10,000 conversaciones concurrentes
- **Read Replicas**: PostgreSQL read replicas para CRM queries
- **Worker Scaling**: M√∫ltiples instancias de workers seg√∫n carga
- **Memory Optimization**: Cleanup de conversaciones inactivas cada hora

### Monitoring

```python
# M√©tricas cr√≠ticas a monitorear
- Active conversations in Redis
- Memory usage per conversation
- Migration queue length  
- Token usage per tenant
- Average response time
- Redis memory usage
- PostgreSQL connection pool
```

### Performance Targets

- **Save Message**: < 50ms (p95)
- **Get Context**: < 100ms (p95)
- **Migration**: < 5 segundos por conversaci√≥n
- **Redis Memory**: < 2GB para 1,000 conversaciones activas
- **CRM Queries**: < 500ms para listado de conversaciones

## üîß Troubleshooting

### Redis Failure Recovery

```python
# Si Redis falla:
1. Conversaciones activas se pierden
2. Fallback: usar PostgreSQL como cache temporal
3. Degraded mode: sin optimizaci√≥n LangChain
4. Recovery: restaurar Redis y recargar desde PostgreSQL
```

### Common Issues

- **Memory Leaks**: Limpiar instancias LangChain de conversaciones migradas
- **Migration Stuck**: Verificar PostgreSQL connectivity y schema
- **Context Too Large**: Verificar token limits por modelo
- **Session Mapping Lost**: Regenerar desde conversaciones activas

## üß™ Testing Strategy

### Unit Tests

```bash
pytest tests/unit/
# - ConversationService methods
# - MemoryManager integration
# - PersistenceManager operations
# - Domain Actions parsing
```

### Integration Tests

```bash
pytest tests/integration/
# - Redis operations
# - LangChain memory behavior
# - Worker processing
# - Migration workflow
```

### Load Tests

```bash
# Simulate high conversation volume
python tests/load/conversation_load_test.py
# Target: 1000 concurrent conversations, 10 msgs/sec per conversation
```

## üîÆ Futuros Enhancements

### An√°lisis Sentimental
- Integraci√≥n con servicios de sentiment analysis
- Tracking de sentiment por conversaci√≥n
- Alertas para sentiment negativo

### Advanced Analytics
- Conversation flow analysis
- Topic modeling